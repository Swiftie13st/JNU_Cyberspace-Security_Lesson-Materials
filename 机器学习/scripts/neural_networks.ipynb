{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b29e0cf2",
   "metadata": {},
   "source": [
    "# 1. 神经网络绪论\n",
    "神经网络是一种模仿生物神经网络（动物的中枢神经系统，特别是大脑）的结构和功能的数学模型或计算模型，用于对函数进行估计或近似。神经网络由大量的人工神经元联结进行计算。\n",
    "\n",
    "\n",
    "## 1.1 与传统的机器学习方法相比\n",
    "区别在于：神经网络没有固定形式，可以DIY。这也决定了神经网络可以解决各种特定问题，只要我们能够针对这个特定的问题，想出一种合理的网络结构与优化目标，就可以解决该问题。这也是目前神经网络创新的主要方向。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaf9587",
   "metadata": {},
   "source": [
    "## 1.2 初次使用\n",
    "通过pip安装 torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bce0c7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.ustc.edu.cn/pypi/web/simple\r\n",
      "Requirement already satisfied: torch in /home/lzy/anaconda3/lib/python3.7/site-packages (1.7.1)\r\n",
      "Requirement already satisfied: numpy in /home/lzy/anaconda3/lib/python3.7/site-packages (from torch) (1.20.3)\r\n",
      "Requirement already satisfied: typing-extensions in /home/lzy/anaconda3/lib/python3.7/site-packages (from torch) (3.10.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install -i https://mirrors.ustc.edu.cn/pypi/web/simple torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd8bf55",
   "metadata": {},
   "source": [
    "# 2 从感知机到神经网络\n",
    "感知器是Frank Rosenblatt在1957年就职于康奈尔航空实验室时所发明的一种人工神经网络。\n",
    "它可以被视为一种最简单形式的前馈神经网络，是一种二元线性分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-terrorist",
   "metadata": {},
   "source": [
    "## 2.1 利用感知机做二分类\n",
    "感知机模型是一个特殊的单层神经网络，单层感知机的输出为1个神经元，在这里我们展示如何使用单层感知机完成二分类任务\n",
    "注意！！！由于神经网络的特殊性，在输入到神经网络之前，需要对输入进行标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-horror",
   "metadata": {},
   "source": [
    "### 2.1.1 单层感知机做二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "juvenile-commitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# 加载乳腺癌数据\n",
    "cancer =datasets.load_breast_cancer()\n",
    "X=cancer.data\n",
    "y=cancer.target\n",
    "\n",
    "# 标准化过程（大家可以尝试注释一下两行比较标准化的重要性）\n",
    "x_norm = np.linalg.norm(X,axis=0)\n",
    "X = X/x_norm\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# 数据划分\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X_tr, y_tr, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "after-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建网络\n",
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.lin = torch.nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 重复使用x以减少现存开销\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "every-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "per = Perceptron(input_dim = 30)\n",
    "# 定义二分类损失\n",
    "loss_func = torch.nn.MSELoss()\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(per.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "modular-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建evaluate 函数\n",
    "def evaluate(net, X, y):\n",
    "    # 将网络转化为测试模式（移除dropout等）\n",
    "    net.eval()\n",
    "    # 强制在验证阶段不保存梯度\n",
    "    with torch.no_grad():\n",
    "        # 通过网络输出结果\n",
    "        out = net(torch.FloatTensor(X)).cpu().data.numpy()\n",
    "        # 将连续数值转化为二分类问题，默认阈值选为0.5\n",
    "        y_pred = np.zeros_like(out)\n",
    "        y_pred[out>0.5] = 1\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, y_pred, pos_label=1)\n",
    "    return metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beneficial-howard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试evaluate 函数\n",
    "evaluate(per,X_va,y_va)\n",
    "# auc 为 0.5 意味着完全随机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loose-improvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数: 0  损失: 0.65031  验证集分数: 0.5  测试集分数: 0.5\n",
      "迭代次数: 10  损失: 0.24668  验证集分数: 0.525  测试集分数: 0.5\n",
      "迭代次数: 20  损失: 0.15359  验证集分数: 0.8875  测试集分数: 0.76687\n",
      "迭代次数: 30  损失: 0.10813  验证集分数: 0.91149  测试集分数: 0.79563\n",
      "迭代次数: 40  损失: 0.09344  验证集分数: 0.9125  测试集分数: 0.77877\n",
      "迭代次数: 50  损失: 0.08938  验证集分数: 0.91824  测试集分数: 0.85516\n",
      "迭代次数: 60  损失: 0.08619  验证集分数: 0.925  测试集分数: 0.81448\n",
      "迭代次数: 70  损失: 0.08308  验证集分数: 0.925  测试集分数: 0.8502\n",
      "迭代次数: 80  损失: 0.08086  验证集分数: 0.91824  测试集分数: 0.86905\n",
      "迭代次数: 90  损失: 0.07916  验证集分数: 0.91824  测试集分数: 0.85714\n",
      "迭代次数: 100  损失: 0.07768  验证集分数: 0.91824  测试集分数: 0.85714\n",
      "迭代次数: 110  损失: 0.07637  验证集分数: 0.91824  测试集分数: 0.85714\n",
      "迭代次数: 120  损失: 0.07519  验证集分数: 0.93074  测试集分数: 0.85714\n",
      "迭代次数: 130  损失: 0.07413  验证集分数: 0.93074  测试集分数: 0.85714\n",
      "迭代次数: 140  损失: 0.07316  验证集分数: 0.93074  测试集分数: 0.86905\n",
      "迭代次数: 150  损失: 0.07227  验证集分数: 0.95  测试集分数: 0.86905\n",
      "迭代次数: 160  损失: 0.07146  验证集分数: 0.95  测试集分数: 0.86905\n",
      "迭代次数: 170  损失: 0.0707  验证集分数: 0.95  测试集分数: 0.88095\n",
      "迭代次数: 180  损失: 0.07001  验证集分数: 0.95  测试集分数: 0.88095\n",
      "迭代次数: 190  损失: 0.06936  验证集分数: 0.9625  测试集分数: 0.88095\n",
      "迭代次数: 200  损失: 0.06876  验证集分数: 0.9625  测试集分数: 0.89286\n",
      "迭代次数: 210  损失: 0.06821  验证集分数: 0.9625  测试集分数: 0.90476\n",
      "迭代次数: 220  损失: 0.06769  验证集分数: 0.9625  测试集分数: 0.90476\n",
      "迭代次数: 230  损失: 0.0672  验证集分数: 0.9625  测试集分数: 0.90476\n",
      "迭代次数: 240  损失: 0.06675  验证集分数: 0.9625  测试集分数: 0.91667\n",
      "迭代次数: 250  损失: 0.06632  验证集分数: 0.9625  测试集分数: 0.91667\n",
      "迭代次数: 260  损失: 0.06592  验证集分数: 0.9625  测试集分数: 0.91667\n",
      "迭代次数: 270  损失: 0.06553  验证集分数: 0.9625  测试集分数: 0.91667\n",
      "迭代次数: 280  损失: 0.06517  验证集分数: 0.9625  测试集分数: 0.91667\n",
      "迭代次数: 290  损失: 0.06483  验证集分数: 0.9625  测试集分数: 0.91667\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    out = per(torch.FloatTensor(X_tr))\n",
    "    loss = loss_func(out, torch.FloatTensor(y_tr).reshape([-1,1]))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 计算验证集与测试集指标\n",
    "    va_score = evaluate(per,X_va,y_va)\n",
    "    ts_score = evaluate(per,X_ts,y_ts)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"迭代次数:\",epoch,\" 损失:\", float(\"%.5f\" % loss.cpu().data.numpy()),\" 验证集分数:\",round(va_score,5),\" 测试集分数:\",round(ts_score,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-investigation",
   "metadata": {},
   "source": [
    "### 2.1.2 带激活函数感知机做二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "secret-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建网络\n",
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.lin = torch.nn.Linear(input_dim, 1)\n",
    "        self.act = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 重复使用x以减少现存开销\n",
    "        x = self.lin(x)\n",
    "        x = self.act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "through-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "per = Perceptron(input_dim = 30)\n",
    "# 定义二分类损失\n",
    "loss_func = torch.nn.MSELoss()\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(per.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suburban-division",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数: 0  损失: 0.10133  验证集分数: 0.92399  测试集分数: 0.80754\n",
      "迭代次数: 10  损失: 0.09221  验证集分数: 0.92399  测试集分数: 0.83135\n",
      "迭代次数: 20  损失: 0.08518  验证集分数: 0.93074  测试集分数: 0.83135\n",
      "迭代次数: 30  损失: 0.07958  验证集分数: 0.93074  测试集分数: 0.85516\n",
      "迭代次数: 40  损失: 0.07501  验证集分数: 0.93074  测试集分数: 0.85516\n",
      "迭代次数: 50  损失: 0.07121  验证集分数: 0.94324  测试集分数: 0.85516\n",
      "迭代次数: 60  损失: 0.068  验证集分数: 0.94324  测试集分数: 0.90278\n",
      "迭代次数: 70  损失: 0.06525  验证集分数: 0.95  测试集分数: 0.90278\n",
      "迭代次数: 80  损失: 0.06285  验证集分数: 0.95  测试集分数: 0.91468\n",
      "迭代次数: 90  损失: 0.06074  验证集分数: 0.95  测试集分数: 0.91468\n",
      "迭代次数: 100  损失: 0.05887  验证集分数: 0.95  测试集分数: 0.92659\n",
      "迭代次数: 110  损失: 0.05718  验证集分数: 0.95  测试集分数: 0.92659\n",
      "迭代次数: 120  损失: 0.05565  验证集分数: 0.95  测试集分数: 0.92659\n",
      "迭代次数: 130  损失: 0.05426  验证集分数: 0.95  测试集分数: 0.93353\n",
      "迭代次数: 140  损失: 0.05298  验证集分数: 0.95  测试集分数: 0.93353\n",
      "迭代次数: 150  损失: 0.0518  验证集分数: 0.95  测试集分数: 0.93353\n",
      "迭代次数: 160  损失: 0.0507  验证集分数: 0.95  测试集分数: 0.93353\n",
      "迭代次数: 170  损失: 0.04968  验证集分数: 0.95  测试集分数: 0.93353\n",
      "迭代次数: 180  损失: 0.04872  验证集分数: 0.9625  测试集分数: 0.94544\n",
      "迭代次数: 190  损失: 0.04782  验证集分数: 0.9625  测试集分数: 0.94544\n",
      "迭代次数: 200  损失: 0.04697  验证集分数: 0.9625  测试集分数: 0.94544\n",
      "迭代次数: 210  损失: 0.04616  验证集分数: 0.9625  测试集分数: 0.94544\n",
      "迭代次数: 220  损失: 0.0454  验证集分数: 0.9625  测试集分数: 0.94544\n",
      "迭代次数: 230  损失: 0.04467  验证集分数: 0.9625  测试集分数: 0.94544\n",
      "迭代次数: 240  损失: 0.04397  验证集分数: 0.9625  测试集分数: 0.94544\n",
      "迭代次数: 250  损失: 0.0433  验证集分数: 0.9625  测试集分数: 0.94544\n",
      "迭代次数: 260  损失: 0.04266  验证集分数: 0.9625  测试集分数: 0.94544\n",
      "迭代次数: 270  损失: 0.04205  验证集分数: 0.9625  测试集分数: 0.94544\n",
      "迭代次数: 280  损失: 0.04146  验证集分数: 0.9625  测试集分数: 0.94544\n",
      "迭代次数: 290  损失: 0.04089  验证集分数: 0.9625  测试集分数: 0.94544\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    out = per(torch.FloatTensor(X_tr))\n",
    "    loss = loss_func(out, torch.FloatTensor(y_tr).reshape([-1,1]))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 计算验证集与测试集指标\n",
    "    va_score = evaluate(per,X_va,y_va)\n",
    "    ts_score = evaluate(per,X_ts,y_ts)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"迭代次数:\",epoch,\" 损失:\", float(\"%.5f\" % loss.cpu().data.numpy()),\" 验证集分数:\",round(va_score,5),\" 测试集分数:\",round(ts_score,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-disorder",
   "metadata": {},
   "source": [
    "### 2.1.2 多层感知机做二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "editorial-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建网络\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(input_dim, 64)\n",
    "        self.act1 = torch.nn.Sigmoid()\n",
    "        self.lin2 = torch.nn.Linear(64, 1)\n",
    "        self.act2 = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 重复使用x以减少现存开销\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "optional-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "mlp = MLP(input_dim = 30)\n",
    "# 定义二分类损失\n",
    "loss_func = torch.nn.MSELoss()\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "precious-investigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数: 0  损失: 0.29847  验证集分数: 0.5  测试集分数: 0.5\n",
      "迭代次数: 10  损失: 0.34352  验证集分数: 0.5  测试集分数: 0.5\n",
      "迭代次数: 20  损失: 0.22963  验证集分数: 0.9277  测试集分数: 0.84921\n",
      "迭代次数: 30  损失: 0.17473  验证集分数: 0.55  测试集分数: 0.52381\n",
      "迭代次数: 40  损失: 0.13277  验证集分数: 0.91149  测试集分数: 0.80556\n",
      "迭代次数: 50  损失: 0.09492  验证集分数: 0.92399  测试集分数: 0.8244\n",
      "迭代次数: 60  损失: 0.0702  验证集分数: 0.92399  测试集分数: 0.87202\n",
      "迭代次数: 70  损失: 0.05556  验证集分数: 0.94899  测试集分数: 0.92659\n",
      "迭代次数: 80  损失: 0.04624  验证集分数: 0.96149  测试集分数: 0.93849\n",
      "迭代次数: 90  损失: 0.04169  验证集分数: 0.96824  测试集分数: 0.94544\n",
      "迭代次数: 100  损失: 0.03855  验证集分数: 0.96824  测试集分数: 0.94544\n",
      "迭代次数: 110  损失: 0.03587  验证集分数: 0.975  测试集分数: 0.94544\n",
      "迭代次数: 120  损失: 0.03349  验证集分数: 0.9875  测试集分数: 0.94544\n",
      "迭代次数: 130  损失: 0.03133  验证集分数: 0.9875  测试集分数: 0.94544\n",
      "迭代次数: 140  损失: 0.02936  验证集分数: 0.9875  测试集分数: 0.94544\n",
      "迭代次数: 150  损失: 0.02754  验证集分数: 0.9875  测试集分数: 0.94544\n",
      "迭代次数: 160  损失: 0.02587  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 170  损失: 0.02434  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 180  损失: 0.02294  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 190  损失: 0.02168  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 200  损失: 0.02054  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 210  损失: 0.01952  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 220  损失: 0.01861  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 230  损失: 0.0178  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 240  损失: 0.01708  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 250  损失: 0.01644  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 260  损失: 0.01587  验证集分数: 0.9875  测试集分数: 0.97619\n",
      "迭代次数: 270  损失: 0.01536  验证集分数: 0.9875  测试集分数: 0.97619\n",
      "迭代次数: 280  损失: 0.01491  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 290  损失: 0.01449  验证集分数: 0.9875  测试集分数: 0.96429\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    out = mlp(torch.FloatTensor(X_tr))\n",
    "    loss = loss_func(out, torch.FloatTensor(y_tr).reshape([-1,1]))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 计算验证集与测试集指标\n",
    "    va_score = evaluate(mlp,X_va,y_va)\n",
    "    ts_score = evaluate(mlp,X_ts,y_ts)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"迭代次数:\",epoch,\" 损失:\", float(\"%.5f\" % loss.cpu().data.numpy()),\" 验证集分数:\",round(va_score,5),\" 测试集分数:\",round(ts_score,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-hampshire",
   "metadata": {},
   "source": [
    "# 3 神经网络激活函数\n",
    "激活函数（Activation Function）是一种添加到人工神经网络中的函数，旨在帮助网络学习数据中的复杂模式。 类似于人类大脑中基于神经元的模型，激活函数最终决定了要发射给下一个神经元的内容。 在人工神经网络中，一个节点的激活函数定义了该节点在给定的输入或输入集合下的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-harvey",
   "metadata": {},
   "source": [
    "### 3.1 激活函数为Tanh+Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sized-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建网络\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(input_dim, 64)\n",
    "        self.act1 = torch.nn.Tanh()\n",
    "        self.lin2 = torch.nn.Linear(64, 1)\n",
    "        self.act2 = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 重复使用x以减少现存开销\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "familiar-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "per = MLP(input_dim = 30)\n",
    "# 定义二分类损失\n",
    "loss_func = torch.nn.MSELoss()\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(per.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sufficient-reasoning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数: 0  损失: 0.25529  验证集分数: 0.5  测试集分数: 0.5\n",
      "迭代次数: 10  损失: 0.05671  验证集分数: 0.95372  测试集分数: 0.91766\n",
      "迭代次数: 20  损失: 0.03884  验证集分数: 0.96824  测试集分数: 0.94544\n",
      "迭代次数: 30  损失: 0.0289  验证集分数: 0.96824  测试集分数: 0.94544\n",
      "迭代次数: 40  损失: 0.02199  验证集分数: 0.975  测试集分数: 0.95238\n",
      "迭代次数: 50  损失: 0.01887  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 60  损失: 0.01684  验证集分数: 0.9875  测试集分数: 0.97619\n",
      "迭代次数: 70  损失: 0.01545  验证集分数: 0.9875  测试集分数: 0.97619\n",
      "迭代次数: 80  损失: 0.01445  验证集分数: 0.9875  测试集分数: 0.97619\n",
      "迭代次数: 90  损失: 0.0134  验证集分数: 0.9875  测试集分数: 0.97619\n",
      "迭代次数: 100  损失: 0.01103  验证集分数: 0.9875  测试集分数: 0.97619\n",
      "迭代次数: 110  损失: 0.01018  验证集分数: 0.975  测试集分数: 0.97619\n",
      "迭代次数: 120  损失: 0.00965  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 130  损失: 0.00931  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 140  损失: 0.00898  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 150  损失: 0.0087  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 160  损失: 0.00845  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 170  损失: 0.00822  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 180  损失: 0.00801  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 190  损失: 0.00783  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 200  损失: 0.00766  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 210  损失: 0.01008  验证集分数: 0.975  测试集分数: 0.95238\n",
      "迭代次数: 220  损失: 0.00766  验证集分数: 0.97399  测试集分数: 0.95734\n",
      "迭代次数: 230  损失: 0.00814  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 240  损失: 0.00728  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 250  损失: 0.00727  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 260  损失: 0.00709  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 270  损失: 0.00695  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 280  损失: 0.00686  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 290  损失: 0.00679  验证集分数: 0.9875  测试集分数: 0.95734\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    out = per(torch.FloatTensor(X_tr))\n",
    "    loss = loss_func(out, torch.FloatTensor(y_tr).reshape([-1,1]))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 计算验证集与测试集指标\n",
    "    va_score = evaluate(per,X_va,y_va)\n",
    "    ts_score = evaluate(per,X_ts,y_ts)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"迭代次数:\",epoch,\" 损失:\", float(\"%.5f\" % loss.cpu().data.numpy()),\" 验证集分数:\",round(va_score,5),\" 测试集分数:\",round(ts_score,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-trout",
   "metadata": {},
   "source": [
    "### 3.2 激活函数为ReLU+Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hourly-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建网络\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(input_dim, 64)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.lin2 = torch.nn.Linear(64, 1)\n",
    "        self.act2 = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 重复使用x以减少现存开销\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "twenty-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "per = MLP(input_dim = 30)\n",
    "# 定义二分类损失\n",
    "loss_func = torch.nn.MSELoss()\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(per.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "certified-stone",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数: 0  损失: 0.01921  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 10  损失: 0.01685  验证集分数: 0.9875  测试集分数: 0.97619\n",
      "迭代次数: 20  损失: 0.01418  验证集分数: 0.9875  测试集分数: 0.97619\n",
      "迭代次数: 30  损失: 0.01241  验证集分数: 0.9875  测试集分数: 0.97619\n",
      "迭代次数: 40  损失: 0.01145  验证集分数: 0.975  测试集分数: 0.96429\n",
      "迭代次数: 50  损失: 0.01091  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 60  损失: 0.01046  验证集分数: 0.9875  测试集分数: 0.96429\n",
      "迭代次数: 70  损失: 0.01007  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 80  损失: 0.00973  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 90  损失: 0.00943  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 100  损失: 0.00915  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 110  损失: 0.0089  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 120  损失: 0.00891  验证集分数: 0.975  测试集分数: 0.95734\n",
      "迭代次数: 130  损失: 0.00854  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 140  损失: 0.00833  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 150  损失: 0.0082  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 160  损失: 0.00803  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 170  损失: 0.00788  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 180  损失: 0.00775  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 190  损失: 0.00763  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 200  损失: 0.00751  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 210  损失: 0.00741  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 220  损失: 0.00731  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 230  损失: 0.00722  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 240  损失: 0.00713  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 250  损失: 0.00705  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 260  损失: 0.00698  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 270  损失: 0.00691  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 280  损失: 0.00685  验证集分数: 0.9875  测试集分数: 0.95734\n",
      "迭代次数: 290  损失: 0.00679  验证集分数: 0.9875  测试集分数: 0.95734\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    out = per(torch.FloatTensor(X_tr))\n",
    "    loss = loss_func(out, torch.FloatTensor(y_tr).reshape([-1,1]))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 计算验证集与测试集指标\n",
    "    va_score = evaluate(per,X_va,y_va)\n",
    "    ts_score = evaluate(per,X_ts,y_ts)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"迭代次数:\",epoch,\" 损失:\", float(\"%.5f\" % loss.cpu().data.numpy()),\" 验证集分数:\",round(va_score,5),\" 测试集分数:\",round(ts_score,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-republic",
   "metadata": {},
   "source": [
    "# 4 神经网络损失函数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-wages",
   "metadata": {},
   "source": [
    "## 4.1 神经网络反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "distant-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建网络\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(input_dim, 64)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.lin2 = torch.nn.Linear(64, 1)\n",
    "        self.act2 = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 重复使用x以减少现存开销\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "handed-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "per = MLP(input_dim = 30)\n",
    "# 定义二分类损失\n",
    "loss_func = torch.nn.MSELoss()\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(per.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "detailed-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型是否定义正确\n",
    "# 注意PyTorch需要提前将输入转化为Tensor形式\n",
    "out = per(torch.FloatTensor(X_tr[:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "mechanical-deployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2611, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 计算Loss\n",
    "# 注意PyTorch需要提前将输入转化为Tensor形式\n",
    "loss = loss_func(out, torch.FloatTensor(y_tr[:10]).reshape([-1,1]))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "otherwise-lebanon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->name: lin1.weight -->grad_requirs: True  -->grad_value: tensor([[-2.0431e-04, -2.0868e-04, -1.9664e-04,  ..., -3.6695e-05,\n",
      "         -2.3156e-04, -2.1938e-04],\n",
      "        [-1.5774e-05, -1.5384e-05, -1.8173e-05,  ..., -7.5233e-05,\n",
      "         -4.9994e-05, -5.0309e-05],\n",
      "        [ 3.7911e-04,  3.7293e-04,  3.6055e-04,  ..., -2.8746e-05,\n",
      "          3.7697e-04,  3.5433e-04],\n",
      "        ...,\n",
      "        [ 2.8349e-05,  2.7886e-05,  2.6961e-05,  ..., -2.1495e-06,\n",
      "          2.8189e-05,  2.6496e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "-->name: lin1.bias -->grad_requirs: True  -->grad_value: tensor([-6.7287e-03,  1.3682e-04,  1.3176e-02,  1.9708e-02,  3.7581e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.8422e-02,\n",
      "         2.4182e-03, -7.0067e-03, -7.7396e-03, -1.0954e-03,  1.4173e-02,\n",
      "        -4.0671e-03,  3.7423e-05,  5.8967e-03,  1.8035e-03,  0.0000e+00,\n",
      "        -1.5358e-02,  5.5946e-04,  6.3043e-03, -8.9257e-03,  0.0000e+00,\n",
      "         1.2777e-02,  2.2447e-03,  1.4367e-03, -3.1324e-03,  0.0000e+00,\n",
      "         1.5262e-02,  0.0000e+00,  0.0000e+00, -1.4337e-03,  0.0000e+00,\n",
      "        -1.6758e-02, -1.9396e-02,  1.6484e-02, -1.3893e-02,  1.6145e-02,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.5485e-03,  0.0000e+00,\n",
      "        -1.1359e-02,  0.0000e+00,  0.0000e+00, -1.0504e-02,  0.0000e+00,\n",
      "         0.0000e+00, -1.4522e-02, -8.4976e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5672e-02,\n",
      "        -2.8269e-03,  9.8527e-04,  0.0000e+00,  0.0000e+00])\n",
      "-->name: lin2.weight -->grad_requirs: True  -->grad_value: tensor([[-0.0098,  0.0002, -0.0086, -0.0065, -0.0257,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000, -0.0114,  0.0003, -0.0007, -0.0233, -0.0126, -0.0068, -0.0264,\n",
      "         -0.0201, -0.0147, -0.0002,  0.0000, -0.0097, -0.0027, -0.0328, -0.0206,\n",
      "          0.0000, -0.0009, -0.0144,  0.0004, -0.0200,  0.0000, -0.0274,  0.0000,\n",
      "          0.0000, -0.0229,  0.0000, -0.0169, -0.0071, -0.0038, -0.0126, -0.0112,\n",
      "          0.0000,  0.0000,  0.0000,  0.0002,  0.0000, -0.0274,  0.0000,  0.0000,\n",
      "         -0.0006,  0.0000,  0.0000, -0.0054, -0.0313,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000, -0.0067, -0.0094, -0.0210,  0.0000,  0.0000]])\n",
      "-->name: lin2.bias -->grad_requirs: True  -->grad_value: tensor([-0.1593])\n"
     ]
    }
   ],
   "source": [
    "# 尝试反向传播Loss\n",
    "# 首先清空上一步的梯度\n",
    "optimizer.zero_grad()\n",
    "# 反向传播Loss\n",
    "loss.backward()\n",
    "# 通过反向传播的Loss优化参数\n",
    "optimizer.step()\n",
    "# 打印梯度\n",
    "for name, parms in per.named_parameters():\n",
    "    print('-->name:', name, '-->grad_requirs:',parms.requires_grad, \\\n",
    "    ' -->grad_value:',parms.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-algebra",
   "metadata": {},
   "source": [
    "## 4.2 神经网络损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-legislature",
   "metadata": {},
   "source": [
    "### 4.2.1 损失函数为交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "63ce9140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# 构建数据加载器 \n",
    "digits =datasets.load_digits()\n",
    "X=digits.data\n",
    "y=digits.target\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# 数据划分\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "80042afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建网络\n",
    "class HMLP(nn.Module):\n",
    "    def __init__(self, input_dim=64, output_dim=10):\n",
    "        super(HMLP, self).__init__()\n",
    "        self.lin1 = nn.Linear(input_dim, 50)\n",
    "        self.lin2 = nn.Linear(50, 40)\n",
    "        self.lin3 = nn.Linear(40, 30)\n",
    "        self.lin4 = nn.Linear(30, output_dim)\n",
    "        self.act = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.lin4(x)\n",
    "        x = self.act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "varied-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "per = HMLP(input_dim = 64)\n",
    "loss_func = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(per.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "apart-general",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数: 0  损失: 2.32587  准确率: 0.16111\n",
      "迭代次数: 10  损失: 0.83983  准确率: 0.83889\n",
      "迭代次数: 20  损失: 0.20071  准确率: 0.93056\n",
      "迭代次数: 30  损失: 0.10795  准确率: 0.95278\n",
      "迭代次数: 40  损失: 0.06872  准确率: 0.95556\n",
      "迭代次数: 50  损失: 0.04497  准确率: 0.95556\n",
      "迭代次数: 60  损失: 0.03186  准确率: 0.95278\n",
      "迭代次数: 70  损失: 0.02449  准确率: 0.96111\n",
      "迭代次数: 80  损失: 0.01958  准确率: 0.96111\n",
      "迭代次数: 90  损失: 0.0163  准确率: 0.96111\n",
      "迭代次数: 100  损失: 0.01406  准确率: 0.96111\n",
      "迭代次数: 110  损失: 0.01242  准确率: 0.96111\n",
      "迭代次数: 120  损失: 0.01121  准确率: 0.96111\n",
      "迭代次数: 130  损失: 0.0103  准确率: 0.96111\n",
      "迭代次数: 140  损失: 0.00961  准确率: 0.96111\n",
      "迭代次数: 150  损失: 0.00908  准确率: 0.95556\n",
      "迭代次数: 160  损失: 0.00867  准确率: 0.95556\n",
      "迭代次数: 170  损失: 0.00834  准确率: 0.95556\n",
      "迭代次数: 180  损失: 0.00808  准确率: 0.95556\n",
      "迭代次数: 190  损失: 0.00787  准确率: 0.95556\n",
      "迭代次数: 200  损失: 0.0077  准确率: 0.95556\n",
      "迭代次数: 210  损失: 0.00755  准确率: 0.95556\n",
      "迭代次数: 220  损失: 0.00744  准确率: 0.95556\n",
      "迭代次数: 230  损失: 0.00733  准确率: 0.95556\n",
      "迭代次数: 240  损失: 0.00725  准确率: 0.95833\n",
      "迭代次数: 250  损失: 0.00717  准确率: 0.95833\n",
      "迭代次数: 260  损失: 0.00711  准确率: 0.95833\n",
      "迭代次数: 270  损失: 0.00705  准确率: 0.95833\n",
      "迭代次数: 280  损失: 0.007  准确率: 0.95833\n",
      "迭代次数: 290  损失: 0.00697  准确率: 0.95833\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(160):\n",
    "    out = per(torch.Tensor(X_tr))\n",
    "    loss = loss_func(out, torch.LongTensor(y_tr))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 计算验证集\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(y_ts)):\n",
    "            res = per(torch.Tensor(X_ts))\n",
    "            y_ts = torch.Tensor(y_ts)\n",
    "            _, pred = torch.max(res.data, dim=1)\n",
    "            total += len(y_ts)\n",
    "            correct += (pred == y_ts).sum().item()\n",
    "    acc = correct/total\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"迭代次数:\",epoch,\" 损失:\", float(\"%.5f\" % loss.cpu().data.numpy()),\" 准确率:\",round(acc,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-mustang",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-kitchen",
   "metadata": {},
   "source": [
    "# 5 神经网络优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-poultry",
   "metadata": {},
   "source": [
    "## 5.1 优化器为SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "verbal-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建网络\n",
    "class HMLP(nn.Module):\n",
    "    def __init__(self, input_dim=64, output_dim=10):\n",
    "        super(HMLP, self).__init__()\n",
    "        self.lin1 = nn.Linear(input_dim, 50)\n",
    "        self.lin2 = nn.Linear(50, 40)\n",
    "        self.lin3 = nn.Linear(40, 30)\n",
    "        self.lin4 = nn.Linear(30, output_dim)\n",
    "        self.act = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.lin4(x)\n",
    "        x = self.act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "peaceful-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "per = HMLP(input_dim = 64)\n",
    "loss_func = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.SGD(per.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "floppy-scottish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数: 0  损失: 2.40365  准确率: 0.12222\n",
      "迭代次数: 10  损失: 2.07646  准确率: 0.37778\n",
      "迭代次数: 20  损失: 1.90038  准确率: 0.48889\n",
      "迭代次数: 30  损失: 1.75784  准确率: 0.51111\n",
      "迭代次数: 40  损失: 1.64091  准确率: 0.525\n",
      "迭代次数: 50  损失: 1.54682  准确率: 0.53611\n",
      "迭代次数: 60  损失: 1.47248  准确率: 0.54167\n",
      "迭代次数: 70  损失: 1.41285  准确率: 0.55556\n",
      "迭代次数: 80  损失: 1.35279  准确率: 0.58056\n",
      "迭代次数: 90  损失: 1.28353  准确率: 0.59722\n",
      "迭代次数: 100  损失: 1.2235  准确率: 0.62222\n",
      "迭代次数: 110  损失: 1.17738  准确率: 0.63056\n",
      "迭代次数: 120  损失: 1.1362  准确率: 0.63611\n",
      "迭代次数: 130  损失: 1.08013  准确率: 0.64722\n",
      "迭代次数: 140  损失: 1.0283  准确率: 0.68056\n",
      "迭代次数: 150  损失: 0.98949  准确率: 0.70556\n",
      "迭代次数: 160  损失: 0.95771  准确率: 0.70833\n",
      "迭代次数: 170  损失: 0.93029  准确率: 0.71111\n",
      "迭代次数: 180  损失: 0.90604  准确率: 0.71944\n",
      "迭代次数: 190  损失: 0.88407  准确率: 0.725\n",
      "迭代次数: 200  损失: 0.86361  准确率: 0.73611\n",
      "迭代次数: 210  损失: 0.84524  准确率: 0.75833\n",
      "迭代次数: 220  损失: 0.82823  准确率: 0.76111\n",
      "迭代次数: 230  损失: 0.81232  准确率: 0.76944\n",
      "迭代次数: 240  损失: 0.79759  准确率: 0.77222\n",
      "迭代次数: 250  损失: 0.78361  准确率: 0.77222\n",
      "迭代次数: 260  损失: 0.77051  准确率: 0.775\n",
      "迭代次数: 270  损失: 0.75812  准确率: 0.775\n",
      "迭代次数: 280  损失: 0.74645  准确率: 0.78056\n",
      "迭代次数: 290  损失: 0.73572  准确率: 0.78611\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(160):\n",
    "    out = per(torch.Tensor(X_tr))\n",
    "    loss = loss_func(out, torch.LongTensor(y_tr))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 计算验证集\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(y_ts)):\n",
    "            res = per(torch.Tensor(X_ts))\n",
    "            y_ts = torch.Tensor(y_ts)\n",
    "            _, pred = torch.max(res.data, dim=1)\n",
    "            total += len(y_ts)\n",
    "            correct += (pred == y_ts).sum().item()\n",
    "    acc = correct/total\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"迭代次数:\",epoch,\" 损失:\", float(\"%.5f\" % loss.cpu().data.numpy()),\" 准确率:\",round(acc,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-canada",
   "metadata": {},
   "source": [
    "### 5.2 优化器为RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "living-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建网络\n",
    "class HMLP(nn.Module):\n",
    "    def __init__(self, input_dim=64, output_dim=10):\n",
    "        super(HMLP, self).__init__()\n",
    "        self.lin1 = nn.Linear(input_dim, 50)\n",
    "        self.lin2 = nn.Linear(50, 40)\n",
    "        self.lin3 = nn.Linear(40, 30)\n",
    "        self.lin4 = nn.Linear(30, output_dim)\n",
    "        self.act = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.lin4(x)\n",
    "        x = self.act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "liable-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "per = HMLP(input_dim = 64)\n",
    "loss_func = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.RMSprop(per.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "renewable-gnome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数: 0  损失: 2.41154  准确率: 0.08889\n",
      "迭代次数: 10  损失: 20.08726  准确率: 0.21111\n",
      "迭代次数: 20  损失: 10.39424  准确率: 0.32222\n",
      "迭代次数: 30  损失: 1.27526  准确率: 0.53056\n",
      "迭代次数: 40  损失: 1.05481  准确率: 0.61389\n",
      "迭代次数: 50  损失: 0.92066  准确率: 0.65278\n",
      "迭代次数: 60  损失: 0.88758  准确率: 0.63056\n",
      "迭代次数: 70  损失: 0.8356  准确率: 0.64167\n",
      "迭代次数: 80  损失: 0.8096  准确率: 0.65\n",
      "迭代次数: 90  损失: 0.78241  准确率: 0.65833\n",
      "迭代次数: 100  损失: 0.76206  准确率: 0.66944\n",
      "迭代次数: 110  损失: 0.73119  准确率: 0.7\n",
      "迭代次数: 120  损失: 0.72762  准确率: 0.69444\n",
      "迭代次数: 130  损失: 0.70508  准确率: 0.70833\n",
      "迭代次数: 140  损失: 0.68948  准确率: 0.71667\n",
      "迭代次数: 150  损失: 0.70041  准确率: 0.69444\n",
      "迭代次数: 160  损失: 0.67685  准确率: 0.71667\n",
      "迭代次数: 170  损失: 0.65502  准确率: 0.71944\n",
      "迭代次数: 180  损失: 0.61843  准确率: 0.73611\n",
      "迭代次数: 190  损失: 0.87469  准确率: 0.55833\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-01caf4c9eca6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0my_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-152-f16daadbf3e5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(160):\n",
    "    out = per(torch.Tensor(X_tr))\n",
    "    loss = loss_func(out, torch.LongTensor(y_tr))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 计算验证集\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(y_ts)):\n",
    "            res = per(torch.Tensor(X_ts))\n",
    "            y_ts = torch.Tensor(y_ts)\n",
    "            _, pred = torch.max(res.data, dim=1)\n",
    "            total += len(y_ts)\n",
    "            correct += (pred == y_ts).sum().item()\n",
    "    acc = correct/total\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"迭代次数:\",epoch,\" 损失:\", float(\"%.5f\" % loss.cpu().data.numpy()),\" 准确率:\",round(acc,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
